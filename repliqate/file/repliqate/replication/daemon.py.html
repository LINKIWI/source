<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>daemon.py - repliqate - SQL -&gt; Kafka replication for append-only workloads</title>
<link rel="icon" type="image/png" href="https://static.kevinlin.info/favicon.png" />
<link rel="alternate" type="application/atom+xml" title="repliqate Atom Feed" href="../../../atom.xml" />
<link rel="alternate" type="application/atom+xml" title="repliqate Atom Feed (tags)" href="../../../tags.xml" />
<style type="text/css">
body {
	color: #000;
	background-color: #fff;
	font-family: monospace;
}

h1, h2, h3, h4, h5, h6 {
	font-size: 1em;
	margin: 0;
}

img, h1, h2 {
	vertical-align: middle;
}

img {
	border: 0;
}

a:target {
	background-color: #ccc;
}

a.d,
a.h,
a.i {
	text-decoration: none;
}

a.line {
	text-decoration: none;
	user-select: none;
}

#blob a {
	color: #555;
}

#blob a:hover {
	color: blue;
	text-decoration: none;
}

table thead td {
	font-weight: bold;
}

table td {
	padding: 0 0.4em;
}

#content table td {
	vertical-align: top;
	white-space: nowrap;
}

#branches tr:hover td,
#tags tr:hover td,
#index tr:hover td,
#log tr:hover td,
#files tr:hover td {
	background-color: #eee;
}

#index tr td:nth-child(2),
#tags tr td:nth-child(3),
#branches tr td:nth-child(3),
#log tr td:nth-child(2) {
	white-space: normal;
}

td.num {
	text-align: right;
}

.desc {
	color: #555;
}

hr {
	border: 0;
	border-top: 1px solid #555;
	height: 1px;
}

pre {
	font-family: monospace;
}

pre a.h {
	color: #00a;
}

.A,
span.i,
pre a.i {
	color: #070;
}

.D,
span.d,
pre a.d {
	color: #e00;
}

pre a.h:hover,
pre a.i:hover,
pre a.d:hover {
	text-decoration: none;
}
</style>
</head>
<body>
<table><tr><td><a href="../../../../"><img src="https://static.kevinlin.info/favicon.png" alt="" width="32" height="32" /></a></td><td><h1>repliqate</h1><span class="desc">SQL -&gt; Kafka replication for append-only workloads</span></td></tr><tr class="url"><td></td><td>git clone <a href="https://source.static.kevinlin.info/repliqate.git">https://source.static.kevinlin.info/repliqate.git</a></td></tr><tr><td></td><td>
<a href="../../../log">Log</a> | <a href="../../../files">Files</a> | <a href="../../../refs">Refs</a> | <a href="../../../file/README.md">README</a></td></tr></table>
<hr/>
<div id="content">
<p> daemon.py (6979B) (<a href="../../../raw/repliqate/replication/daemon.py">raw</a>)</p><hr/><pre id="blob">
<a href="#l1" class="line" id="l1">      1</a> import logging
<a href="#l2" class="line" id="l2">      2</a> import time
<a href="#l3" class="line" id="l3">      3</a> import traceback
<a href="#l4" class="line" id="l4">      4</a> 
<a href="#l5" class="line" id="l5">      5</a> from repliqate.db.kv import KeyValueStoreClient
<a href="#l6" class="line" id="l6">      6</a> from repliqate.db.sql import SQLDBClient
<a href="#l7" class="line" id="l7">      7</a> from repliqate.metrics.hook import NoopMetricsHook
<a href="#l8" class="line" id="l8">      8</a> from repliqate.metrics.hook import StatsdMetricsHook
<a href="#l9" class="line" id="l9">      9</a> from repliqate.metrics.timer import ExecutionTimer
<a href="#l10" class="line" id="l10">     10</a> from repliqate.stream.message import Message
<a href="#l11" class="line" id="l11">     11</a> from repliqate.stream.producer import StreamProducerClient
<a href="#l12" class="line" id="l12">     12</a> 
<a href="#l13" class="line" id="l13">     13</a> 
<a href="#l14" class="line" id="l14">     14</a> def offset_contention_resolution(primary, secondary):
<a href="#l15" class="line" id="l15">     15</a>     &quot;&quot;&quot;
<a href="#l16" class="line" id="l16">     16</a>     In event of a read conflict, always use the latest offset so to minimize re-publishing messages
<a href="#l17" class="line" id="l17">     17</a>     that have already been published.
<a href="#l18" class="line" id="l18">     18</a> 
<a href="#l19" class="line" id="l19">     19</a>     :param primary: Value read from the primary datastore.
<a href="#l20" class="line" id="l20">     20</a>     :param secondary: Value read from the secondary datastore.
<a href="#l21" class="line" id="l21">     21</a>     :return: The greater of the two values.
<a href="#l22" class="line" id="l22">     22</a>     &quot;&quot;&quot;
<a href="#l23" class="line" id="l23">     23</a>     if primary is None:
<a href="#l24" class="line" id="l24">     24</a>         return secondary
<a href="#l25" class="line" id="l25">     25</a> 
<a href="#l26" class="line" id="l26">     26</a>     if secondary is None:
<a href="#l27" class="line" id="l27">     27</a>         return primary
<a href="#l28" class="line" id="l28">     28</a> 
<a href="#l29" class="line" id="l29">     29</a>     if int(primary) &gt; int(secondary):
<a href="#l30" class="line" id="l30">     30</a>         return primary
<a href="#l31" class="line" id="l31">     31</a> 
<a href="#l32" class="line" id="l32">     32</a>     return secondary
<a href="#l33" class="line" id="l33">     33</a> 
<a href="#l34" class="line" id="l34">     34</a> 
<a href="#l35" class="line" id="l35">     35</a> class ReplicationDaemon(object):
<a href="#l36" class="line" id="l36">     36</a>     &quot;&quot;&quot;
<a href="#l37" class="line" id="l37">     37</a>     Daemon for periodically executing the main replication routine.
<a href="#l38" class="line" id="l38">     38</a>     &quot;&quot;&quot;
<a href="#l39" class="line" id="l39">     39</a> 
<a href="#l40" class="line" id="l40">     40</a>     def __init__(self, config):
<a href="#l41" class="line" id="l41">     41</a>         &quot;&quot;&quot;
<a href="#l42" class="line" id="l42">     42</a>         Create a daemon instance from a valid config object.
<a href="#l43" class="line" id="l43">     43</a> 
<a href="#l44" class="line" id="l44">     44</a>         :param config: Config instance.
<a href="#l45" class="line" id="l45">     45</a>         &quot;&quot;&quot;
<a href="#l46" class="line" id="l46">     46</a>         self.logger = logging.getLogger(&#39;repliqate&#39;)
<a href="#l47" class="line" id="l47">     47</a> 
<a href="#l48" class="line" id="l48">     48</a>         # Parameters
<a href="#l49" class="line" id="l49">     49</a>         self.name = config.get(&#39;name&#39;)
<a href="#l50" class="line" id="l50">     50</a>         self.poll_interval = config.get(&#39;replication.poll_interval_sec&#39;)
<a href="#l51" class="line" id="l51">     51</a>         self.sql_table = config.get(&#39;replication.sql_source.table&#39;)
<a href="#l52" class="line" id="l52">     52</a>         self.sql_primary_key = config.get(&#39;replication.sql_source.primary_key&#39;)
<a href="#l53" class="line" id="l53">     53</a>         self.sql_fields = config.get(&#39;replication.sql_source.fields&#39;)
<a href="#l54" class="line" id="l54">     54</a>         self.sql_limit = config.get(&#39;replication.sql_source.limit&#39;)
<a href="#l55" class="line" id="l55">     55</a>         self.kafka_topic = config.get(&#39;replication.kafka_target.topic&#39;)
<a href="#l56" class="line" id="l56">     56</a> 
<a href="#l57" class="line" id="l57">     57</a>         # Clients
<a href="#l58" class="line" id="l58">     58</a>         self.db = SQLDBClient(
<a href="#l59" class="line" id="l59">     59</a>             db_uri=config.get(&#39;replication.sql_source.uri&#39;),
<a href="#l60" class="line" id="l60">     60</a>             table=self.sql_table,
<a href="#l61" class="line" id="l61">     61</a>         )
<a href="#l62" class="line" id="l62">     62</a>         self.kv = KeyValueStoreClient(
<a href="#l63" class="line" id="l63">     63</a>             addr=config.get(&#39;redis_addr&#39;),
<a href="#l64" class="line" id="l64">     64</a>             prefix=&#39;repliqate&#39;,
<a href="#l65" class="line" id="l65">     65</a>             contention_resolution=offset_contention_resolution,
<a href="#l66" class="line" id="l66">     66</a>         )
<a href="#l67" class="line" id="l67">     67</a>         self.stream = StreamProducerClient(
<a href="#l68" class="line" id="l68">     68</a>             brokers=config.get(&#39;replication.kafka_target.brokers&#39;),
<a href="#l69" class="line" id="l69">     69</a>             topic=self.kafka_topic,
<a href="#l70" class="line" id="l70">     70</a>         )
<a href="#l71" class="line" id="l71">     71</a> 
<a href="#l72" class="line" id="l72">     72</a>         statsd_addr = config.get(&#39;statsd_addr&#39;)
<a href="#l73" class="line" id="l73">     73</a>         if statsd_addr:
<a href="#l74" class="line" id="l74">     74</a>             self.metrics = StatsdMetricsHook(self.name, statsd_addr)
<a href="#l75" class="line" id="l75">     75</a>             self.logger.debug(
<a href="#l76" class="line" id="l76">     76</a>                 &#39;statsd address provided; enabling metrics reporting: addr={}&#39;.format(statsd_addr),
<a href="#l77" class="line" id="l77">     77</a>             )
<a href="#l78" class="line" id="l78">     78</a>         else:
<a href="#l79" class="line" id="l79">     79</a>             self.metrics = NoopMetricsHook()
<a href="#l80" class="line" id="l80">     80</a>             self.logger.debug(&#39;statsd address omitted; disabling metrics reporting&#39;)
<a href="#l81" class="line" id="l81">     81</a> 
<a href="#l82" class="line" id="l82">     82</a>         self.logger.info(&#39;initialized replication daemon successfully&#39;)
<a href="#l83" class="line" id="l83">     83</a> 
<a href="#l84" class="line" id="l84">     84</a>     def start(self):
<a href="#l85" class="line" id="l85">     85</a>         &quot;&quot;&quot;
<a href="#l86" class="line" id="l86">     86</a>         Start the replication routine, continuing indefinitely.
<a href="#l87" class="line" id="l87">     87</a>         &quot;&quot;&quot;
<a href="#l88" class="line" id="l88">     88</a>         self.logger.info(&#39;starting daemon: poll_interval_sec={}&#39;.format(self.poll_interval))
<a href="#l89" class="line" id="l89">     89</a> 
<a href="#l90" class="line" id="l90">     90</a>         while True:
<a href="#l91" class="line" id="l91">     91</a>             try:
<a href="#l92" class="line" id="l92">     92</a>                 rows, offset = self._replication_fetch_publish()
<a href="#l93" class="line" id="l93">     93</a>                 self.logger.info(
<a href="#l94" class="line" id="l94">     94</a>                     &#39;completed replication iteration: rows={} offset={}&#39;.format(rows, offset)
<a href="#l95" class="line" id="l95">     95</a>                 )
<a href="#l96" class="line" id="l96">     96</a>             except Exception:
<a href="#l97" class="line" id="l97">     97</a>                 self.logger.error(
<a href="#l98" class="line" id="l98">     98</a>                     &#39;encountered error during replication; will abort current iteration&#39;
<a href="#l99" class="line" id="l99">     99</a>                 )
<a href="#l100" class="line" id="l100">    100</a>                 traceback.print_exc()
<a href="#l101" class="line" id="l101">    101</a> 
<a href="#l102" class="line" id="l102">    102</a>             self.logger.debug(
<a href="#l103" class="line" id="l103">    103</a>                 &#39;sleeping before next iteration: duration_sec={}&#39;.format(self.poll_interval),
<a href="#l104" class="line" id="l104">    104</a>             )
<a href="#l105" class="line" id="l105">    105</a>             time.sleep(self.poll_interval)
<a href="#l106" class="line" id="l106">    106</a> 
<a href="#l107" class="line" id="l107">    107</a>     def close(self):
<a href="#l108" class="line" id="l108">    108</a>         &quot;&quot;&quot;
<a href="#l109" class="line" id="l109">    109</a>         Close active connections.
<a href="#l110" class="line" id="l110">    110</a>         &quot;&quot;&quot;
<a href="#l111" class="line" id="l111">    111</a>         self.logger.debug(&#39;stopping daemon, closing stateful connections&#39;)
<a href="#l112" class="line" id="l112">    112</a> 
<a href="#l113" class="line" id="l113">    113</a>         self.db.close()
<a href="#l114" class="line" id="l114">    114</a>         self.stream.close()
<a href="#l115" class="line" id="l115">    115</a> 
<a href="#l116" class="line" id="l116">    116</a>     def _replication_fetch_publish(self):
<a href="#l117" class="line" id="l117">    117</a>         &quot;&quot;&quot;
<a href="#l118" class="line" id="l118">    118</a>         Execute a single iteration of the replication routine.
<a href="#l119" class="line" id="l119">    119</a> 
<a href="#l120" class="line" id="l120">    120</a>         :return: A tuple of (number of rows published, new committed offset).
<a href="#l121" class="line" id="l121">    121</a>         &quot;&quot;&quot;
<a href="#l122" class="line" id="l122">    122</a>         exec_timer = ExecutionTimer()
<a href="#l123" class="line" id="l123">    123</a>         kv_closure = self.kv.closure(
<a href="#l124" class="line" id="l124">    124</a>             namespace=&#39;replication&#39;,
<a href="#l125" class="line" id="l125">    125</a>             key=&#39;offset&#39;,
<a href="#l126" class="line" id="l126">    126</a>             tags={&#39;name&#39;: self.name, &#39;table&#39;: self.sql_table, &#39;topic&#39;: self.kafka_topic},
<a href="#l127" class="line" id="l127">    127</a>         )
<a href="#l128" class="line" id="l128">    128</a> 
<a href="#l129" class="line" id="l129">    129</a>         with exec_timer.timer():
<a href="#l130" class="line" id="l130">    130</a>             offset = kv_closure.get() or 0
<a href="#l131" class="line" id="l131">    131</a>         self.metrics.emit_store_read(success=True, duration=exec_timer.duration())
<a href="#l132" class="line" id="l132">    132</a> 
<a href="#l133" class="line" id="l133">    133</a>         try:
<a href="#l134" class="line" id="l134">    134</a>             self.logger.debug(&#39;querying source with primary key offset: offset={}&#39;.format(offset))
<a href="#l135" class="line" id="l135">    135</a> 
<a href="#l136" class="line" id="l136">    136</a>             with exec_timer.timer():
<a href="#l137" class="line" id="l137">    137</a>                 rows = self.db.query(
<a href="#l138" class="line" id="l138">    138</a>                     fields=[self.db.field(field) for field in self.sql_fields],
<a href="#l139" class="line" id="l139">    139</a>                     criteria=self.db.field(self.sql_primary_key) &gt; int(offset),
<a href="#l140" class="line" id="l140">    140</a>                     limit=self.sql_limit,
<a href="#l141" class="line" id="l141">    141</a>                 )
<a href="#l142" class="line" id="l142">    142</a> 
<a href="#l143" class="line" id="l143">    143</a>             self.metrics.emit_sql_read(
<a href="#l144" class="line" id="l144">    144</a>                 success=True,
<a href="#l145" class="line" id="l145">    145</a>                 table=self.sql_table,
<a href="#l146" class="line" id="l146">    146</a>                 num_rows=len(rows),
<a href="#l147" class="line" id="l147">    147</a>                 duration=exec_timer.duration(),
<a href="#l148" class="line" id="l148">    148</a>             )
<a href="#l149" class="line" id="l149">    149</a>         except Exception as e:
<a href="#l150" class="line" id="l150">    150</a>             self.logger.error(&#39;sql source read failure: exception={}&#39;.format(e))
<a href="#l151" class="line" id="l151">    151</a>             self.metrics.emit_sql_read(
<a href="#l152" class="line" id="l152">    152</a>                 success=False,
<a href="#l153" class="line" id="l153">    153</a>                 table=self.sql_table,
<a href="#l154" class="line" id="l154">    154</a>                 num_rows=0,
<a href="#l155" class="line" id="l155">    155</a>                 duration=exec_timer.duration(),
<a href="#l156" class="line" id="l156">    156</a>             )
<a href="#l157" class="line" id="l157">    157</a>             raise e
<a href="#l158" class="line" id="l158">    158</a> 
<a href="#l159" class="line" id="l159">    159</a>         if not rows:
<a href="#l160" class="line" id="l160">    160</a>             self.logger.debug(&#39;no new rows since last fetch; aborting&#39;)
<a href="#l161" class="line" id="l161">    161</a>             return 0, -1
<a href="#l162" class="line" id="l162">    162</a> 
<a href="#l163" class="line" id="l163">    163</a>         self.logger.debug(&#39;serializing messages from fetched rows: num_rows={}&#39;.format(len(rows)))
<a href="#l164" class="line" id="l164">    164</a>         next_offset = -1
<a href="#l165" class="line" id="l165">    165</a>         messages = [
<a href="#l166" class="line" id="l166">    166</a>             Message(self.name, self.sql_table, row)
<a href="#l167" class="line" id="l167">    167</a>             for row in rows
<a href="#l168" class="line" id="l168">    168</a>         ]
<a href="#l169" class="line" id="l169">    169</a> 
<a href="#l170" class="line" id="l170">    170</a>         for message in messages:
<a href="#l171" class="line" id="l171">    171</a>             next_offset = message.data[self.sql_primary_key]
<a href="#l172" class="line" id="l172">    172</a> 
<a href="#l173" class="line" id="l173">    173</a>             try:
<a href="#l174" class="line" id="l174">    174</a>                 self.logger.debug(&#39;publishing message: message={}&#39;.format(message))
<a href="#l175" class="line" id="l175">    175</a> 
<a href="#l176" class="line" id="l176">    176</a>                 with exec_timer.timer():
<a href="#l177" class="line" id="l177">    177</a>                     self.stream.publish(message.serialize())
<a href="#l178" class="line" id="l178">    178</a> 
<a href="#l179" class="line" id="l179">    179</a>                 self.metrics.emit_kafka_publish(
<a href="#l180" class="line" id="l180">    180</a>                     success=True,
<a href="#l181" class="line" id="l181">    181</a>                     topic=self.kafka_topic,
<a href="#l182" class="line" id="l182">    182</a>                     duration=exec_timer.duration(),
<a href="#l183" class="line" id="l183">    183</a>                 )
<a href="#l184" class="line" id="l184">    184</a>             except Exception as e:
<a href="#l185" class="line" id="l185">    185</a>                 self.logger.error(&#39;kafka publication failure: exception={}&#39;.format(e))
<a href="#l186" class="line" id="l186">    186</a>                 self.metrics.emit_kafka_publish(
<a href="#l187" class="line" id="l187">    187</a>                     success=False,
<a href="#l188" class="line" id="l188">    188</a>                     topic=self.kafka_topic,
<a href="#l189" class="line" id="l189">    189</a>                     duration=exec_timer.duration(),
<a href="#l190" class="line" id="l190">    190</a>                 )
<a href="#l191" class="line" id="l191">    191</a>                 raise e
<a href="#l192" class="line" id="l192">    192</a> 
<a href="#l193" class="line" id="l193">    193</a>             self.logger.debug(&#39;storing next primary key offset: offset={}&#39;.format(next_offset))
<a href="#l194" class="line" id="l194">    194</a>             with exec_timer.timer():
<a href="#l195" class="line" id="l195">    195</a>                 kv_closure.set(next_offset)
<a href="#l196" class="line" id="l196">    196</a>             self.metrics.emit_store_write(success=True, duration=exec_timer.duration())
<a href="#l197" class="line" id="l197">    197</a>             self.metrics.emit_offset_position(table=self.sql_table, offset=next_offset)
<a href="#l198" class="line" id="l198">    198</a> 
<a href="#l199" class="line" id="l199">    199</a>         return len(rows), next_offset
</pre>
</div>
</body>
</html>
